{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation della Lezione4, in Lezione5 Huggingface tokenizer invece che Spacy\n",
    "vedi Notebook prof, ma attento che su questo hai preso appunti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GJ-S7BMlE3TJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /home/naska/miniconda3/lib/python3.9/site-packages (0.13.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "62Ap-HTCpyMM"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from tensorflow.data import Dataset\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import GRUCell, Embedding, Attention, Dense\n",
    "import json\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.normalizers import  Lowercase\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ps6Q2QbnmORQ",
    "outputId": "ea2540d8-5f8d-4dd5-c21c-12090c768459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-20 14:20:06--  https://www.manythings.org/anki/ita-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110, 198.41.0.4, 199.9.14.201, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8220355 (7.8M) [application/zip]\n",
      "Saving to: ‘ita-eng.zip.1’\n",
      "\n",
      "ita-eng.zip.1       100%[===================>]   7.84M  2.92MB/s    in 2.7s    \n",
      "\n",
      "2023-09-20 14:20:10 (2.92 MB/s) - ‘ita-eng.zip.1’ saved [8220355/8220355]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.manythings.org/anki/ita-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3KENBgWo2Jz",
    "outputId": "64ed4c54-8307-4137-ce8f-008033cfe9f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ita-eng.zip\n",
      "replace ita.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip ita-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "-wesJLDoVWX3"
   },
   "outputs": [],
   "source": [
    "UNK = \"<UNK>\"\n",
    "BOS = \"<BOS>\"\n",
    "EOS = \"<EOS>\"\n",
    "PAD = \"<PAD>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "bpyzYDyt3dq2"
   },
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "BOS_IDX = 2\n",
    "EOS_IDX = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWkspfB2H1jo"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4tZPWUFpqdK"
   },
   "source": [
    "# tokenizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "HIKYYPcbJU5i"
   },
   "outputs": [],
   "source": [
    "special_tokens = [PAD, UNK, BOS, EOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ShC-TDwuHATa"
   },
   "outputs": [],
   "source": [
    "en_tokenizer = Tokenizer(WordPiece(unk_token=UNK))\n",
    "en_tokenizer.normalizer = Lowercase()\n",
    "en_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "it_tokenizer = Tokenizer(WordPiece(unk_token=UNK))\n",
    "it_tokenizer.normalizer = Lowercase()\n",
    "it_tokenizer.pre_tokenizer = Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "FgeBC8rS_-PV"
   },
   "outputs": [],
   "source": [
    "def lang_iterator(lang=\"en\"):\n",
    "    with open(\"ita.txt\", \"r\") as f:\n",
    "        while line:=f.readline()[:-1]:\n",
    "            en_sent, it_sent, _ = line.split(\"\\t\")\n",
    "            yield en_sent if lang==\"en\" else it_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "fDBsaBTf_DN-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "en_tokenizer.train_from_iterator(lang_iterator(\"en\"), trainer=WordPieceTrainer(vocab_size=10_000, special_tokens=special_tokens))\n",
    "it_tokenizer.train_from_iterator(lang_iterator(\"it\"), trainer=WordPieceTrainer(vocab_size=10_000, special_tokens=special_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Hn71AFFXKXnd"
   },
   "outputs": [],
   "source": [
    "en_vocab = en_tokenizer.get_vocab()\n",
    "it_vocab = it_tokenizer.get_vocab()\n",
    "en_vocab_inv = {v:k for k, v in en_vocab.items()}\n",
    "it_vocab_inv = {v:k for k, v in it_vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap3gBed41Ysh"
   },
   "source": [
    "# split train-validation-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AIRsEu7c1j1W"
   },
   "outputs": [],
   "source": [
    "def split_file(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    num_rows = len(lines)\n",
    "    shuffled_row_idxs = random.sample(list(range(num_rows)), k=num_rows)\n",
    "\n",
    "    train_idxs = shuffled_row_idxs[:int(num_rows*0.6)]\n",
    "    val_idxs = shuffled_row_idxs[int(num_rows*0.6):int(num_rows*0.8)]\n",
    "    test_idxs = shuffled_row_idxs[int(num_rows*0.8):]\n",
    "\n",
    "    # train\n",
    "    with open(\"train.txt\", \"w\") as f:\n",
    "        f.writelines([lines[idx] for idx in train_idxs])\n",
    "\n",
    "    # validation\n",
    "    with open(\"val.txt\", \"w\") as f:\n",
    "        f.writelines([lines[idx] for idx in val_idxs])\n",
    "\n",
    "    # test\n",
    "    with open(\"test.txt\", \"w\") as f:\n",
    "        f.writelines([lines[idx] for idx in test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nANyIJ533-lC"
   },
   "outputs": [],
   "source": [
    "split_file(\"ita.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0kWmX3b-C-3"
   },
   "source": [
    "# Generatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Xahh-257-QKj"
   },
   "outputs": [],
   "source": [
    "def dataset_generator(filepath, en_dict, it_dict, en_tokenizer, it_tokenizer):\n",
    "    def gen():\n",
    "        with open(filepath, \"r\") as f:\n",
    "            while (line := f.readline()) is not None:\n",
    "                en_sentence, it_sentence, *_ = line.split(\"\\t\")\n",
    "                en_sentence_tokenized = en_tokenizer.encode(en_sentence).tokens\n",
    "                it_sentence_tokenized = it_tokenizer.encode(it_sentence).tokens\n",
    "                src_sentence_tokenized = en_sentence_tokenized + [EOS]\n",
    "                tgt_sentence_in_tokenized = [BOS] + it_sentence_tokenized\n",
    "                tgt_sentence_out_tokenized = it_sentence_tokenized.copy() + [EOS]\n",
    "\n",
    "                src_sentence_encoded = [en_dict.get(token, en_dict[UNK]) for token in src_sentence_tokenized]\n",
    "                tgt_sentence_in_encoded = [it_dict.get(token, it_dict[UNK]) for token in tgt_sentence_in_tokenized]\n",
    "                tgt_sentence_out_encoded = [it_dict.get(token, it_dict[UNK]) for token in tgt_sentence_out_tokenized]\n",
    "\n",
    "                yield (src_sentence_encoded, tgt_sentence_in_encoded), tgt_sentence_out_encoded # input, target in e target_out\n",
    "\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wdd7bvBmYWjA"
   },
   "outputs": [],
   "source": [
    "# for (src, tgt_in), tgt_out in dataset_generator(\"val.txt\", en_vocab, it_vocab, Tokenizer(\"en\"), Tokenizer(\"it\")):\n",
    "#     print(src)\n",
    "#     print(tgt_in)\n",
    "#     print(tgt_out)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "lpgWbHFvYxDP"
   },
   "outputs": [],
   "source": [
    "trainset = Dataset.from_generator(\n",
    "    generator=dataset_generator(\"train.txt\", en_vocab, it_vocab, en_tokenizer, it_tokenizer),\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(None,), dtype=tf.int32), tf.TensorSpec(shape=(None,), dtype=tf.int32)),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32))\n",
    ")\n",
    "\n",
    "valset = Dataset.from_generator(\n",
    "    generator=dataset_generator(\"val.txt\", en_vocab, it_vocab, en_tokenizer, it_tokenizer),\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(None,), dtype=tf.int32), tf.TensorSpec(shape=(None,), dtype=tf.int32)),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32))\n",
    ")\n",
    "\n",
    "testset = Dataset.from_generator(\n",
    "    generator=dataset_generator(\"test.txt\", en_vocab, it_vocab, en_tokenizer, it_tokenizer),\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(None,), dtype=tf.int32), tf.TensorSpec(shape=(None,), dtype=tf.int32)),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "SCWAwZtFbio_"
   },
   "outputs": [],
   "source": [
    "trainset = trainset.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n",
    "trainset = trainset.padded_batch(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "EklA1mMxwMae"
   },
   "outputs": [],
   "source": [
    "class TextEncoderDecoder:\n",
    "    def __init__(self, en_vocab, en_vocab_inv, it_vocab, it_vocab_inv):\n",
    "        self.en_vocab = en_vocab\n",
    "        self.en_vocab_inv = en_vocab_inv\n",
    "        self.it_vocab = it_vocab\n",
    "        self.it_vocab_inv = it_vocab_inv\n",
    "        self.nlp_it = spacy.load(\"it_core_news_md\")\n",
    "        self.nlp_en = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "    def encode(self, text, language):\n",
    "        vocab = self.en_vocab if language == \"en\" else self.it_vocab\n",
    "        nlp = self.nlp_en if language == \"en\" else self.nlp_it\n",
    "        tokenized_text = [token.text.lower() for token in nlp(text)]\n",
    "        return [vocab.get(token, vocab[UNK]) for token in tokenized_text]\n",
    "\n",
    "    def decode(self, coded_text, language):\n",
    "        vocab_inv = self.en_vocab_inv if language == \"en\" else self.it_vocab_inv\n",
    "        return [vocab_inv[code] for code in coded_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7SO2N9jf7tx"
   },
   "source": [
    "# Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-pyk5t36rbk3"
   },
   "outputs": [],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self, vocabulary_size, embedding_size, recurrent_layers, recurrent_units, **kwargs):\n",
    "        \"\"\"\n",
    "        args\n",
    "        ----\n",
    "        - vocabulary_size (int): including special tokens (<BOS>, <EOS>, <UNK>)\n",
    "        - embedding_size (int): dimensione dello spazio degli embedding\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # embedding\n",
    "        # 0 index mean padding\n",
    "        # input: batch_size x seq_length\n",
    "        self.embedding = Embedding(\n",
    "            vocabulary_size, embedding_size, mask_zero=True) # costruisce matrice\n",
    "        # output: batch_size x seq_length x embedding_size (ogni frase rappr da una matrice)\n",
    "\n",
    "        gru_cells = [GRUCell(recurrent_units) for _ in range(recurrent_layers)]\n",
    "\n",
    "        stacked_cells = tf.keras.layers.StackedRNNCells(gru_cells)\n",
    "        self.gru_layer = tf.keras.layers.RNN(stacked_cells, return_state=True, return_sequences=True)\n",
    "\n",
    "    def call(self, data, training=None):\n",
    "        # data.shape: batch_size x seq_len\n",
    "        x = self.embedding(data, training=training)\n",
    "        # data.shape: batch_size x seq_len x embedding_size\n",
    "        output, *state = self.gru_layer(x, training=training)\n",
    "\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 10, 128]), 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esempio\n",
    "encoder = Encoder(vocabulary_size=10_000,\n",
    "       embedding_size = 128,\n",
    "       recurrent_layers = 2,\n",
    "       recurrent_units = 128\n",
    "       )\n",
    "\n",
    "sentences = tf.random.uniform([2,10], 0, 100, tf.int32)\n",
    "output, state = encoder(sentences)\n",
    "output.shape, len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[1].shape # batch_size x 128 (embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "rG0MTvBGrxz2"
   },
   "outputs": [],
   "source": [
    "class Decoder(keras.Model):\n",
    "    def __init__(self, vocabulary_size, embedding_size, recurrent_layers, recurrent_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.recurrent_layers = recurrent_layers\n",
    "        self.recurrent_units = recurrent_units\n",
    "\n",
    "        self.embedding = Embedding(\n",
    "            vocabulary_size, embedding_size, mask_zero=True)\n",
    "\n",
    "        gru_cells = [GRUCell(recurrent_units) for _ in range(recurrent_layers)]\n",
    "\n",
    "        stacked_cells = tf.keras.layers.StackedRNNCells(gru_cells)\n",
    "        self.gru_layer = tf.keras.layers.RNN(stacked_cells, return_state=True)\n",
    "\n",
    "\n",
    "    def call(self, target_in, encoder_output, rnn_state, training=None):\n",
    "        # target_in.shape = batch_size\n",
    "        # target_in_embedded.shape = batch_size x embedding_dim\n",
    "        target_in_embedded = tf.squeeze(self.embedding(tf.expand_dims(target_in, axis=1), training=training))\n",
    "\n",
    "        # creo il contesto\n",
    "        # context.shape = batch_size x recurrent_units\n",
    "\n",
    "        context = encoder_output[:, -1, :] # il contesto è l'output dell'encoder\n",
    "\n",
    "\n",
    "        # concateno embedding della parola e contesto\n",
    "        # word_and_context.shape = batch_size x 1 x (recurrent_units+embedding_dim)\n",
    "        word_and_context = tf.expand_dims(tf.concat([target_in_embedded, context], axis=1), axis=1)\n",
    "\n",
    "        # output.shape = batch_size x recurrent_units\n",
    "        output, *state = self.gru_layer(word_and_context, initial_state=rnn_state, training=training)\n",
    "\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "IyqDnFlc3Cpv"
   },
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "q6_9ew1pr0jm"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(keras.Model):\n",
    "    def __init__(self, vocabulary_size, embedding_size, recurrent_layers, recurrent_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        assert embedding_size == recurrent_units, \"must be embedding_size == recurrent_units\"\n",
    "\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.recurrent_layers = recurrent_layers\n",
    "        self.recurrent_units = recurrent_units\n",
    "\n",
    "\n",
    "        self.encoder = Encoder(vocabulary_size, embedding_size,\n",
    "                               recurrent_layers, recurrent_units)\n",
    "        self.decoder = Decoder(vocabulary_size, embedding_size, recurrent_layers,\n",
    "                               recurrent_units)\n",
    "\n",
    "        self.dense = Dense(vocabulary_size, \"softmax\")\n",
    "\n",
    "    def call(self, data, training=None, max_sentence_length=MAX_SENTENCE_LENGTH):\n",
    "        # unpack data\n",
    "        src_sentences, dst_sentences = data\n",
    "\n",
    "        probs = []\n",
    "\n",
    "        # encoder call\n",
    "        # encoder_output.shape = batch x len_sentences x encoder_recurrent_units\n",
    "        encoder_output, encoder_state = self.encoder(src_sentences, training=training)\n",
    "\n",
    "        seq_len = max_sentence_length if not training else tf.shape(dst_sentences)[1]\n",
    "        decoder_state = encoder_state\n",
    "        for i in range(seq_len):\n",
    "            if not training:\n",
    "                if i == 0:\n",
    "                    decoder_input = tf.fill(dims=[tf.shape(src_sentences)[0]], value=BOS_IDX)\n",
    "                else:\n",
    "                    decoder_input = tf.math.argmax(probs[-1], axis=1)\n",
    "            else:\n",
    "                decoder_input = dst_sentences[:, i]\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input, encoder_output, decoder_state, training=training)\n",
    "            probs.append(self.dense(decoder_output))\n",
    "\n",
    "        # decoder_output.shape = batch_size x max_sentence_length x vocabulary_size\n",
    "        return tf.stack(probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "XYBHzwjapKGt"
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    y_true_reshaped = tf.reshape(y_true, [-1])\n",
    "    y_pred_reshaped = tf.reshape(y_pred, [-1, y_pred.shape[-1]])\n",
    "    scc = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        reduction=tf.keras.losses.Reduction.NONE)\n",
    "    results = scc(y_true_reshaped, y_pred_reshaped)\n",
    "    mask = tf.cast(y_true_reshaped != 0, tf.float32)\n",
    "    return tf.reduce_sum(results*mask) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdTs4kiC36CO"
   },
   "source": [
    "# Addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(32, 18), dtype=int32, numpy=\n",
       "  array([[1805,  154,   29, 2085,   14,    3,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 128,  535,  205,  507,  716,  137,  128,  486,   13, 5966, 1551,\n",
       "          2224,  156,  171,  283,  529,    4,    3],\n",
       "         [ 154,    9,  231,  472,  752,   14,    3,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 521,   37, 1389,  187, 1871,   28,    3,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 194,  140,  156,  289,  418,   28,    3,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,    9,   41,  938,  283,  446,  642,   14,    3,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,  918,  411,  986,  324,  472,   14,    3,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 128,  952,  137,  152,  128, 5610,  169,  128, 1204,   14,    3,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,  165,  271,   14,    3,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 155,  165,   29,  854,  944,  508,  119,  140,   14,    3,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,  524,  365,  722,  271,   14,    3,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 194,  176,  122,  140,  205,  191, 4521,   28,    3,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 271,  182, 6752,   14,    3,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 242,    9,  231,  223,  169,  411,   14,    3,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,  926,    9,   48,  465,  155,  495,   14,    3,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 346,    9,   47,  128, 2087,   28,    3,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,  324,  211,  119,  873,  153,  318,  181,  229, 3112,   14,\n",
       "             3,    0,    0,    0,    0,    0,    0],\n",
       "         [ 125,  478,    9,   48,  884,  119, 2288,  128, 6717,   14,    3,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,  165, 5079,  499, 2034, 1183,   14,    3,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 156,  684,  159, 1847,   14,    3,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,  209,  155,  125,  896,  122,   14,    3,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 122,  521,  465,  128,  399,   14,    3,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [1777,  125,   14,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,  636,  191, 4521,   14,    3,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 122,  355,  475,  155,  122,  447,  161,   14,    3,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 125,  412,  161,  155,  146, 1701,   87,  212,    6, 4140,   14,\n",
       "             3,    0,    0,    0,    0,    0,    0],\n",
       "         [ 140,  122,  340,  447,  125,   28,    3,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [  37,    9,  247,  367,  230, 2620, 1086,   12, 7113,  452,   14,\n",
       "             3,    0,    0,    0,    0,    0,    0],\n",
       "         [ 125,  190,  951,  155,   14,    3,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [   5,  265, 1248,  964,  128, 1067, 1530,    5,   37,  171, 1270,\n",
       "             3,    0,    0,    0,    0,    0,    0],\n",
       "         [ 176,  122,  357,  529,   28,    3,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 125,  412,  212,  119,  370,  119, 1439,   14,    3,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0]], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(32, 21), dtype=int32, numpy=\n",
       "  array([[   2,  249, 7245,  147, 1670,   14,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  158,  685,  177,  936,  770,  170,  169, 2897,  215,   13,\n",
       "          1354,   77,  370,  135,  152,  407,  179,  138,  427,    4],\n",
       "         [   2, 2771,  673,   14,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  174,  838, 4849,  158,  557, 2258,   28,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  138,  303,  407,  487,  495,   28,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  170, 2687, 3075,  153,  596,  939,   14,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  162,  655,  152, 2066,  440,  457,  138, 1625,   14,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  149, 1116,   59,  531, 2430,  470,  972,   14,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,   31,    9,  474,   14,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  232,  202,  303,  849, 2169,  207,  306,   14,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  162, 2738, 1606, 3553,   14,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  152,  156,  379,  177,   37,  729, 6200,   28,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  250,  170,  526, 5262,   14,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  427,  879, 2703,   29,  457,   14,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  162,  139,  250, 6751,   74,   14,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  301,    9,   59,  149, 2088,   28,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  655, 1512, 3998,  274,  153,  149,  360, 4010,   14,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  133,  139,  232,  154, 1035,  138, 4585,  222,  593,  189,\n",
       "            14,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  170,  592, 1418, 2574,  441, 2533,  197,   14,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  407,  738,  147, 2231,   14,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  290,  152,  133,  209,  156, 6101,   14,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  508,  857,  158,  556,   14,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2, 8439,  135,  133,   14,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  187,  899,  158,  331, 8336,   14,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  139, 1502,  333,  152,  174, 4433,   14,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  133,  174,  156,  355,  152, 2274, 7043,    6,   29,  229,\n",
       "            14,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  184, 3215,  533,  133,   28,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  170,  414,  318, 3168, 1351,   12, 1072,  956,  138,  293,\n",
       "            14,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  133,  249,  508, 1958,   14,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,    5,  694,  156, 1430,  149, 1444, 1838,    5,  162, 1560,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  369,  156,  169,  241,   28,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,  133,  761,   29,  229,  138,  516,  177, 1741,   14,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "        dtype=int32)>),\n",
       " <tf.Tensor: shape=(32, 21), dtype=int32, numpy=\n",
       " array([[ 249, 7245,  147, 1670,   14,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 158,  685,  177,  936,  770,  170,  169, 2897,  215,   13, 1354,\n",
       "           77,  370,  135,  152,  407,  179,  138,  427,    4,    3],\n",
       "        [2771,  673,   14,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 174,  838, 4849,  158,  557, 2258,   28,    3,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 138,  303,  407,  487,  495,   28,    3,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 170, 2687, 3075,  153,  596,  939,   14,    3,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 162,  655,  152, 2066,  440,  457,  138, 1625,   14,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 149, 1116,   59,  531, 2430,  470,  972,   14,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [  31,    9,  474,   14,    3,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 232,  202,  303,  849, 2169,  207,  306,   14,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 162, 2738, 1606, 3553,   14,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 152,  156,  379,  177,   37,  729, 6200,   28,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 250,  170,  526, 5262,   14,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 427,  879, 2703,   29,  457,   14,    3,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 162,  139,  250, 6751,   74,   14,    3,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 301,    9,   59,  149, 2088,   28,    3,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 655, 1512, 3998,  274,  153,  149,  360, 4010,   14,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 133,  139,  232,  154, 1035,  138, 4585,  222,  593,  189,   14,\n",
       "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 170,  592, 1418, 2574,  441, 2533,  197,   14,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 407,  738,  147, 2231,   14,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 290,  152,  133,  209,  156, 6101,   14,    3,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 508,  857,  158,  556,   14,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [8439,  135,  133,   14,    3,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 187,  899,  158,  331, 8336,   14,    3,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 139, 1502,  333,  152,  174, 4433,   14,    3,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 133,  174,  156,  355,  152, 2274, 7043,    6,   29,  229,   14,\n",
       "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 184, 3215,  533,  133,   28,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 170,  414,  318, 3168, 1351,   12, 1072,  956,  138,  293,   14,\n",
       "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 133,  249,  508, 1958,   14,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   5,  694,  156, 1430,  149, 1444, 1838,    5,  162, 1560,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 369,  156,  169,  241,   28,    3,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 133,  761,   29,  229,  138,  516,  177, 1741,   14,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "       dtype=int32)>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainset)) # input, target in, target output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "xcSDNyEv38uv"
   },
   "outputs": [],
   "source": [
    "encoder_decoder = EncoderDecoder(vocabulary_size=10_000, embedding_size=256, recurrent_layers=2, recurrent_units=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "jYp2P-Pm-qCx"
   },
   "outputs": [],
   "source": [
    "encoder_decoder.compile(optimizer=keras.optimizers.Adam(), loss=custom_loss, run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tOGJLwh--2vC",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f03c5237-d05e-4709-aa7b-89cfed7d7e53",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 12/100 [==>...........................] - ETA: 1:55 - loss: 8.6067"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mencoder_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1338\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_function\u001b[39m(iterator):\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1322\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1319\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1322\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1324\u001b[0m     outputs,\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1326\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1327\u001b[0m )\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3250\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3248\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:4048\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4046\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4047\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4048\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1303\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1303\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1080\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;66;03m# Run forward pass.\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m-> 1080\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    567\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1149\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[82], line 41\u001b[0m, in \u001b[0;36mEncoderDecoder.call\u001b[0;34m(self, data, training, max_sentence_length)\u001b[0m\n\u001b[1;32m     39\u001b[0m         decoder_input \u001b[38;5;241m=\u001b[39m dst_sentences[:, i]\n\u001b[1;32m     40\u001b[0m     decoder_output, decoder_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(decoder_input, encoder_output, decoder_state, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m---> 41\u001b[0m     probs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_output\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# decoder_output.shape = batch_size x max_sentence_length x vocabulary_size\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mstack(probs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/base_layer.py:1128\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     name_scope \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_unnested_name_scope()\n\u001b[1;32m   1126\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autographed_call()\n\u001b[0;32m-> 1128\u001b[0m call_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtraceback_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minject_argument_info_in_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcall_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m (type \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mExitStack() \u001b[38;5;28;01mas\u001b[39;00m namescope_stack:\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_name_scope_on_model_declaration_enabled:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:160\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback\u001b[0;34m(fn, object_name)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecorator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/tf_decorator.py:136\u001b[0m, in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decorator_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m   decorator_name \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\n\u001b[0;32m--> 136\u001b[0m decorator \u001b[38;5;241m=\u001b[39m \u001b[43mTFDecorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecorator_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorator_doc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdecorator_argspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28msetattr\u001b[39m(decorator_func, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_tf_decorator\u001b[39m\u001b[38;5;124m'\u001b[39m, decorator)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Objects that are callables (e.g., a functools.partial object) may not have\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# the following attributes.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/tf_decorator.py:332\u001b[0m, in \u001b[0;36mTFDecorator.__init__\u001b[0;34m(self, decorator_name, target, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(target):\n\u001b[1;32m    331\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__signature__ \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;66;03m# Certain callables such as builtins can not be inspected for signature.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/inspect.py:3113\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/inspect.py:2862\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/inspect.py:2266\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a callable object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj))\n\u001b[1;32m   2263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types\u001b[38;5;241m.\u001b[39mMethodType):\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m# In this case we skip the first parameter of the underlying\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# function (usually `self` or `cls`).\u001b[39;00m\n\u001b[0;32m-> 2266\u001b[0m     sig \u001b[38;5;241m=\u001b[39m \u001b[43m_get_signature_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_bound_arg:\n\u001b[1;32m   2269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _signature_bound_method(sig)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/inspect.py:2325\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2323\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2324\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2330\u001b[0m                                    skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/inspect.py:2172\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;66;03m# Parameter information.\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m func_code \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\n\u001b[0;32m-> 2172\u001b[0m pos_count \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_code\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_argcount\u001b[49m\n\u001b[1;32m   2173\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m func_code\u001b[38;5;241m.\u001b[39mco_varnames\n\u001b[1;32m   2174\u001b[0m posonly_count \u001b[38;5;241m=\u001b[39m func_code\u001b[38;5;241m.\u001b[39mco_posonlyargcount\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder_decoder.fit(x=trainset, steps_per_epoch=100, epochs=100, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKPQq5eloQwY"
   },
   "outputs": [],
   "source": [
    "encoder_decoder.save_weights(\"weights_100.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Pk6iNeGhZGz",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvdCSGuS-89a",
    "outputId": "7a0a0016-ecfb-4db1-a5e2-d3e2305a9eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sono un insegnante di francese , non sono bravo in un amico . <EOS> . <EOS> . <EOS> . <EOS>\n"
     ]
    }
   ],
   "source": [
    "sentence = \"i am a good guy and my home is beautiful\"\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "tokens = [t.text.lower() for t in nlp(sentence)]\n",
    "idxs = [en_vocab.get(t, en_vocab[UNK]) for t in tokens]\n",
    "translation = encoder_decoder.generate(tf.reshape(tf.constant(idxs), [1, -1]))\n",
    "print(\" \".join([it_vocab_inv[idx] for idx in translation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altro\n",
    "Spiegazione Matrice di Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 14:46:25.555001: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-20 14:46:25.619760: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-20 14:46:25.620416: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-20 14:46:26.655965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(input_dim=10_000, output_dim=512, mask_zero=True)\n",
    "# vocab_size, dimensione del vettore parola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tf.random.uniform([2, 10], 0, 100, tf.int32) # 2 frasi lunghe 10 parole (interi da 0 a 100)\n",
    "embedded_sentences = embedding(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 10, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences.shape # ogni frase, 10 token, ciascun token in un vettore da 512 float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences[0][0].shape # frase 1, token 1 (è un vettore lungo 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
       "array([-2.50312928e-02,  1.83144473e-02, -6.85974211e-03, -2.88465749e-02,\n",
       "        4.67611887e-02, -2.56500840e-02, -2.82975193e-02, -4.49316502e-02,\n",
       "       -1.24897584e-02,  8.83637741e-03,  4.66066636e-02, -3.94867174e-02,\n",
       "       -2.75575761e-02,  1.59662701e-02,  3.64848636e-02,  1.82839967e-02,\n",
       "       -4.03087512e-02, -2.99840216e-02,  2.91905552e-03, -9.92680714e-03,\n",
       "       -9.50132683e-03, -1.70045868e-02,  3.31894271e-02, -4.06564251e-02,\n",
       "        2.63581388e-02,  8.62586498e-03, -3.44862714e-02, -4.37368043e-02,\n",
       "       -4.69430201e-02,  4.11962382e-02, -1.64128169e-02,  3.92797701e-02,\n",
       "        8.78310204e-03,  3.46171297e-02,  2.92851590e-02, -3.85824814e-02,\n",
       "        1.38792656e-02, -2.36201771e-02,  2.26876773e-02,  4.99265231e-02,\n",
       "       -1.63786300e-02, -4.24662344e-02,  3.01709026e-03, -8.41565058e-03,\n",
       "       -2.91646607e-02, -4.14339192e-02, -7.65029341e-03,  2.03201063e-02,\n",
       "        3.95124666e-02, -2.64043733e-03,  1.53302066e-02,  3.15786041e-02,\n",
       "       -3.98516878e-02,  2.44563818e-03, -9.02898610e-05, -4.21592705e-02,\n",
       "       -4.43892479e-02, -4.78835702e-02,  2.66259946e-02, -2.55419370e-02,\n",
       "        1.53784864e-02,  4.08847369e-02,  4.72542979e-02,  9.50932503e-04,\n",
       "        2.79379748e-02, -1.99881941e-03, -3.05014253e-02,  3.35164331e-02,\n",
       "        3.28866281e-02, -8.51905346e-03, -3.48501205e-02, -4.40997146e-02,\n",
       "       -4.65541594e-02, -4.76203077e-02,  7.86522776e-03,  2.12287046e-02,\n",
       "       -6.08044863e-03, -6.03824854e-03, -1.32259242e-02,  1.99191831e-02,\n",
       "        1.47990696e-02, -3.11174393e-02,  3.69195603e-02, -8.86337832e-03,\n",
       "       -1.84212103e-02, -3.94298062e-02,  3.15765627e-02, -4.68212254e-02,\n",
       "       -2.35117599e-03,  2.88208015e-02, -4.45504561e-02, -3.51096988e-02,\n",
       "        1.23216398e-02,  4.92696054e-02, -1.69030577e-03,  2.95400061e-02,\n",
       "       -4.55909967e-02,  1.62351467e-02, -3.94880548e-02,  3.69810127e-02,\n",
       "       -1.40208825e-02, -3.14250365e-02, -2.89325472e-02, -2.58986596e-02,\n",
       "       -4.79988828e-02, -2.07830425e-02, -3.36361751e-02, -1.64273009e-02,\n",
       "        1.37292631e-02,  1.85486563e-02, -4.40459251e-02, -2.75197159e-02,\n",
       "        3.98049839e-02, -2.95777321e-02,  3.49292271e-02, -2.53479835e-02,\n",
       "       -1.30614527e-02, -3.53776440e-02, -2.99390797e-02, -4.32221778e-02,\n",
       "       -4.60243225e-03, -4.88667563e-03,  2.82671116e-02,  4.76779453e-02,\n",
       "       -2.83965711e-02, -5.69378212e-03, -5.58530167e-03, -1.03752501e-02,\n",
       "       -6.32866472e-03,  3.88242044e-02,  4.90255021e-02, -3.17833200e-02,\n",
       "        1.87618621e-02,  4.73922603e-02, -3.40444818e-02,  2.54032649e-02,\n",
       "       -1.98075660e-02, -4.31099199e-02, -3.17163467e-02,  2.25488208e-02,\n",
       "       -5.45328856e-03,  2.33957432e-02, -1.47627108e-02,  1.88286230e-03,\n",
       "       -4.03408036e-02, -4.39009443e-02,  2.07590126e-02, -7.16603920e-03,\n",
       "       -1.10599175e-02,  1.54642798e-02, -2.81728860e-02,  6.40517473e-03,\n",
       "        1.99798457e-02,  4.98810746e-02,  2.31699236e-02, -1.09835640e-02,\n",
       "       -3.20804343e-02, -1.83977261e-02,  3.36267687e-02,  2.18469016e-02,\n",
       "       -3.77075188e-02, -1.74712017e-03, -2.44623777e-02, -3.62668633e-02,\n",
       "       -1.26198307e-02, -1.82037726e-02, -2.62837168e-02, -8.11755657e-03,\n",
       "       -2.33981758e-03,  3.27578224e-02,  4.25849296e-02, -3.31359282e-02,\n",
       "       -3.38337570e-03,  1.49199106e-02, -4.39895988e-02,  2.08912008e-02,\n",
       "        7.04442337e-03, -3.38242874e-02,  2.36799754e-02, -4.19849977e-02,\n",
       "       -4.45194505e-02, -3.24386358e-02, -3.30769643e-02, -2.39284169e-02,\n",
       "        2.11146586e-02, -2.28040814e-02, -3.27471383e-02, -1.07684247e-02,\n",
       "        4.76062931e-02,  3.46306227e-02,  3.08441781e-02,  4.05375473e-02,\n",
       "       -3.70725878e-02, -1.83836445e-02,  4.15815227e-02,  1.96109749e-02,\n",
       "        4.49711569e-02, -4.17207591e-02,  1.39187612e-02, -4.99510765e-03,\n",
       "        2.16083787e-02, -2.69203074e-02,  7.14795664e-03,  4.16244306e-02,\n",
       "        2.70032920e-02, -3.58825214e-02,  7.48127699e-03,  2.58409269e-02,\n",
       "        3.11151855e-02,  3.04412358e-02, -3.34392861e-03,  1.93576477e-02,\n",
       "        1.27987936e-03,  4.73125242e-02, -3.08194645e-02,  1.25893392e-02,\n",
       "        1.36185624e-02, -9.00501013e-03, -4.40896414e-02,  1.82376616e-02,\n",
       "        5.97747415e-03, -5.19337505e-03, -3.05562094e-03, -1.32370107e-02,\n",
       "        4.04394530e-02, -1.33140087e-02, -4.12155278e-02, -2.00038087e-02,\n",
       "       -1.01700537e-02, -1.66224241e-02,  2.40564607e-02, -3.06968931e-02,\n",
       "        4.15384434e-02, -4.51187752e-02,  4.59264033e-02, -3.69814634e-02,\n",
       "        4.40636985e-02, -2.49876864e-02,  1.54091828e-02, -4.84599918e-03,\n",
       "        3.99115421e-02,  4.17330302e-02, -4.65045683e-02, -2.67002825e-02,\n",
       "        3.52693535e-02, -4.62379344e-02,  4.69473116e-02,  1.06307119e-03,\n",
       "        1.32436492e-02, -4.80143428e-02,  3.19181569e-02, -2.70370394e-03,\n",
       "       -3.96653898e-02,  2.35174187e-02,  2.19769366e-02, -1.82005875e-02,\n",
       "       -3.76752615e-02, -1.75515898e-02,  2.82695144e-03, -4.50158231e-02,\n",
       "       -1.61676034e-02, -1.47951245e-02, -2.84799188e-03, -2.12496519e-03,\n",
       "        3.27935480e-02,  1.08101591e-02, -3.27951908e-02, -4.64108475e-02,\n",
       "        2.69034244e-02,  5.36106527e-04, -2.23902706e-02,  1.80815719e-02,\n",
       "        1.57156698e-02, -3.65041718e-02,  3.67507376e-02, -1.71186216e-02,\n",
       "       -2.14332938e-02,  1.24138817e-02,  2.61747278e-02,  4.59746011e-02,\n",
       "       -1.35403872e-03, -1.54557079e-03,  3.45635526e-02, -2.55164038e-02,\n",
       "       -1.66370869e-02,  4.46725003e-02, -2.67043002e-02,  3.72512601e-02,\n",
       "        4.91437428e-02,  5.98561019e-04, -6.91485405e-03,  1.49742626e-02,\n",
       "       -3.74308601e-02, -3.01772244e-02, -2.99805645e-02, -2.49537118e-02,\n",
       "        3.58265378e-02,  1.64323561e-02,  3.47399153e-02, -3.37419510e-02,\n",
       "       -1.15876570e-02, -2.87572276e-02, -4.93444577e-02,  7.68877566e-04,\n",
       "       -4.32439558e-02,  1.13507397e-02, -4.19899821e-02,  2.31964029e-02,\n",
       "       -3.77530828e-02,  4.65325750e-02,  1.12628117e-02, -2.95355208e-02,\n",
       "        1.02394931e-02, -4.44237962e-02, -1.65771320e-03,  8.44151899e-03,\n",
       "       -6.85464591e-04,  4.41829227e-02,  1.90240182e-02, -7.60592520e-04,\n",
       "        2.88674980e-03,  1.60255693e-02,  3.58884223e-02, -1.48407929e-02,\n",
       "        9.50496271e-03,  4.48352359e-02,  2.71970741e-02,  4.17095162e-02,\n",
       "       -1.33283734e-02,  1.23632662e-02,  1.83688067e-02,  3.98553871e-02,\n",
       "       -2.67024171e-02,  1.10211484e-02,  2.83029787e-02, -3.97045240e-02,\n",
       "       -7.82877207e-03, -2.34474428e-02,  3.45586203e-02,  7.88336992e-03,\n",
       "       -3.11786067e-02, -6.17464632e-03,  1.99741460e-02, -3.01787853e-02,\n",
       "       -1.81531906e-03,  3.25796641e-02, -1.18721351e-02, -2.85804402e-02,\n",
       "       -2.20513586e-02, -1.99852716e-02, -2.46552955e-02,  5.54897636e-03,\n",
       "       -7.26455450e-03, -7.42191076e-03, -2.70650033e-02,  3.05056088e-02,\n",
       "       -1.69803947e-03,  3.28144766e-02, -2.13069208e-02, -3.36257219e-02,\n",
       "       -3.51710096e-02, -1.84945576e-02,  2.67640240e-02,  3.89556773e-02,\n",
       "       -3.53474729e-02, -2.98180338e-02,  1.26890875e-02,  3.35328095e-02,\n",
       "       -3.33601125e-02,  3.15537937e-02,  1.43454932e-02, -1.60458460e-02,\n",
       "        4.86172363e-03, -6.56121969e-03,  2.60844342e-02,  5.99552318e-03,\n",
       "        2.85299905e-02,  4.96145152e-02,  1.20344870e-02,  1.22643113e-02,\n",
       "       -2.25170385e-02, -4.17970121e-04,  4.20390405e-02, -4.48242091e-02,\n",
       "        2.64674462e-02,  4.77260351e-03, -3.42842117e-02, -1.16714239e-02,\n",
       "        1.75086409e-03,  6.49213791e-03,  4.35028411e-02, -8.03072378e-03,\n",
       "       -1.69460401e-02, -1.80197470e-02,  5.73848560e-03,  4.70969416e-02,\n",
       "        2.94263400e-02, -3.52630131e-02,  2.96275690e-03, -3.37837562e-02,\n",
       "        3.58461998e-02, -2.57092845e-02,  2.73303725e-02, -2.93312557e-02,\n",
       "        2.45609172e-02, -3.72914672e-02,  4.44688909e-02,  2.61863358e-02,\n",
       "        3.01785804e-02, -2.66942028e-02,  2.99805738e-02,  3.07230391e-02,\n",
       "       -4.17223945e-02, -6.91764429e-03,  1.43708326e-02,  6.89305365e-04,\n",
       "       -2.85727382e-02,  3.77954878e-02,  4.65064906e-02,  2.48775221e-02,\n",
       "       -3.91360894e-02,  1.07508525e-02, -8.69107246e-03,  2.63203047e-02,\n",
       "       -1.65963285e-02,  1.35495178e-02,  1.60261728e-02,  3.98859419e-02,\n",
       "       -3.75117883e-02,  3.78896631e-02,  3.09091248e-02,  1.52438767e-02,\n",
       "        3.16031314e-02,  3.30449678e-02,  3.80262025e-02, -2.31263041e-02,\n",
       "       -4.47356217e-02, -9.81105492e-03, -3.98244485e-02, -4.76572663e-03,\n",
       "        1.28454007e-02,  1.26459859e-02,  1.86622255e-02, -2.19881665e-02,\n",
       "       -1.27508864e-02,  3.47069018e-02, -2.12416295e-02, -1.10706091e-02,\n",
       "       -4.19664159e-02, -2.65457518e-02, -4.78785634e-02, -8.03369284e-03,\n",
       "       -1.29569992e-02, -3.69966999e-02,  1.34286322e-02, -2.45789532e-02,\n",
       "       -1.16994753e-02, -4.96952422e-02,  3.49226035e-02, -2.24512573e-02,\n",
       "       -2.96412837e-02,  3.18528339e-03, -4.33778055e-02,  3.26147936e-02,\n",
       "        3.34381498e-02, -3.52122188e-02, -3.64618376e-03, -3.01214699e-02,\n",
       "        4.67523970e-02,  2.31586732e-02, -2.53572222e-02,  1.16288662e-04,\n",
       "        3.62163521e-02, -4.16526794e-02,  1.32894777e-02,  6.93341345e-03,\n",
       "        1.04719773e-02, -4.91276756e-02, -1.11213550e-02,  2.69553773e-02,\n",
       "        2.72802226e-02,  2.46624239e-02,  8.42425972e-03,  4.94588949e-02,\n",
       "        2.08118297e-02, -4.89238650e-03, -2.62727588e-03,  6.09628111e-03,\n",
       "       -1.83600783e-02, -2.97275428e-02, -2.17496511e-02,  3.73584069e-02,\n",
       "       -1.26085505e-02, -3.88560519e-02, -4.42624092e-04,  3.53391878e-02,\n",
       "       -3.49174142e-02, -4.86188307e-02, -3.71993706e-03,  1.66052580e-03,\n",
       "       -2.21526623e-03,  1.84336789e-02,  2.32498907e-02,  3.20203640e-02,\n",
       "       -7.02108070e-03, -1.24058351e-02,  4.75141443e-02, -1.98908895e-03,\n",
       "       -1.30291805e-02, -3.63013856e-02, -3.64423767e-02, -4.47357073e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.17471176e-02,  1.21394880e-02,  2.51705386e-02,  3.73667739e-02,\n",
       "       -1.82010904e-02, -3.31496149e-02, -4.23372909e-03,  2.48690955e-02,\n",
       "        3.16639207e-02, -4.75274920e-02,  3.64082493e-02,  1.34738125e-02,\n",
       "       -2.69374494e-02,  1.45352371e-02,  3.54732983e-02,  1.10796466e-02,\n",
       "       -2.89683100e-02, -1.54553652e-02,  1.92291774e-02, -2.38754749e-02,\n",
       "        2.51053087e-02,  5.17425686e-03, -1.40281767e-03,  1.62094496e-02,\n",
       "        4.55679931e-02,  3.00576948e-02, -8.76331329e-03, -3.21155936e-02,\n",
       "        1.78758390e-02, -2.60051247e-02,  1.10275745e-02, -2.50389706e-02,\n",
       "       -1.36180967e-03, -2.39867568e-02, -2.47322563e-02,  2.42419951e-02,\n",
       "        2.50582956e-02, -3.39053422e-02, -4.07314412e-02, -4.81655262e-02,\n",
       "        1.61961205e-02,  4.51124050e-02, -4.22927737e-02, -2.66074017e-03,\n",
       "       -3.63420695e-04, -3.25978026e-02,  2.40233801e-02,  1.13788620e-02,\n",
       "        3.56761850e-02,  3.81277092e-02, -2.86096819e-02, -2.03917865e-02,\n",
       "        1.59296282e-02,  1.50207020e-02, -1.32659301e-02,  2.89690495e-03,\n",
       "       -4.14089188e-02, -4.34760824e-02, -1.36357546e-03,  2.96639092e-02,\n",
       "        2.20465399e-02, -3.61494310e-02,  3.66043709e-02, -2.63520367e-02,\n",
       "       -4.94731553e-02, -1.01794004e-02,  4.39532138e-02, -3.54268439e-02,\n",
       "        2.29793899e-02, -4.82456461e-02, -3.73280756e-02,  4.66899984e-02,\n",
       "       -4.46281917e-02,  2.47677304e-02,  3.74605320e-02,  2.01232471e-02,\n",
       "       -4.81821075e-02,  3.15988064e-03,  9.51447338e-03,  9.66687128e-03,\n",
       "        2.29967274e-02, -1.84689760e-02, -5.60428947e-03,  4.84739207e-02,\n",
       "       -5.03386185e-03,  4.63777296e-02,  1.93840601e-02,  2.29832195e-02,\n",
       "        3.96879055e-02,  7.34531879e-03,  2.55575031e-03,  4.85943072e-02,\n",
       "        2.20354646e-03, -4.40868512e-02,  7.20727444e-03,  1.01672485e-03,\n",
       "       -3.22751626e-02,  3.64461653e-02, -1.04462020e-02, -3.70382294e-02,\n",
       "        2.55175680e-03,  3.12088989e-02,  1.62346400e-02, -1.41463876e-02,\n",
       "        2.44171880e-02,  1.21084079e-02, -2.70570647e-02,  3.61708067e-02,\n",
       "       -3.34719792e-02,  3.25006582e-02,  1.44423880e-02, -2.21630335e-02,\n",
       "        4.19723988e-03, -3.64818089e-02, -4.80548032e-02,  3.58265974e-02,\n",
       "       -4.96353172e-02, -3.22716720e-02,  4.09896858e-02,  2.69750468e-02,\n",
       "       -2.14732885e-02,  2.74481513e-02, -4.13341448e-03,  1.84351318e-02,\n",
       "       -3.98795381e-02,  2.76255123e-02, -1.85826048e-02,  3.08820717e-02,\n",
       "       -2.73381006e-02, -2.51271483e-02, -4.95936275e-02,  1.83682479e-02,\n",
       "       -8.41433927e-03,  1.61688812e-02, -4.10647877e-02, -4.10831198e-02,\n",
       "       -2.90833246e-02, -4.07394059e-02, -2.62399446e-02,  9.10631567e-03,\n",
       "       -4.48401682e-02,  5.51961362e-04,  2.25907601e-02, -4.78540733e-03,\n",
       "        7.50930235e-03,  1.82800926e-02,  1.26526468e-02, -1.11982338e-02,\n",
       "        1.34143345e-02, -3.11253555e-02, -1.05302222e-02,  3.00597288e-02,\n",
       "        3.14633586e-02,  4.66901176e-02,  3.06156985e-02,  4.11979854e-05,\n",
       "       -6.05245680e-03, -2.24602465e-02, -3.74926329e-02,  3.32435630e-02,\n",
       "        3.99596803e-02, -1.39361620e-02,  4.15993854e-03, -1.89512614e-02,\n",
       "       -3.81345637e-02, -4.27753441e-02,  2.04906128e-02, -2.63724215e-02,\n",
       "       -2.75875684e-02, -4.02463898e-02, -1.33419409e-02, -6.28409535e-03,\n",
       "       -3.12244780e-02, -4.85299118e-02,  2.91378237e-02,  2.29015462e-02,\n",
       "       -5.09289652e-03,  1.69700123e-02, -5.27135283e-03,  1.12646446e-02,\n",
       "       -3.54823954e-02,  1.98815502e-02,  6.74536079e-03, -3.00162192e-02,\n",
       "        2.91180499e-02,  1.02102160e-02,  8.41320679e-03,  1.56719424e-02,\n",
       "        2.28802301e-02,  6.96854666e-03, -3.17576900e-02,  1.85377114e-02,\n",
       "       -4.92698662e-02,  1.36202089e-02, -4.12705652e-02, -1.29283294e-02,\n",
       "       -3.34490091e-04, -1.42745264e-02,  1.79425590e-02, -4.64318283e-02,\n",
       "        1.02131367e-02, -1.09667070e-02,  3.70006301e-02, -1.37281306e-02,\n",
       "        4.04579155e-02,  3.73765491e-02, -4.48308699e-02,  2.93414332e-02,\n",
       "       -3.15641649e-02,  3.66169550e-02, -2.65960339e-02, -4.26705852e-02,\n",
       "       -3.15010548e-04,  4.53359522e-02,  2.99709477e-02, -8.10985640e-03,\n",
       "        4.39713262e-02, -2.67823339e-02, -3.31461802e-02,  2.35767998e-02,\n",
       "       -4.43674810e-02, -2.78472193e-02, -1.67220719e-02, -4.15358171e-02,\n",
       "        4.36748192e-03,  3.21543217e-03, -2.10285187e-04,  4.03899811e-02,\n",
       "        1.92616694e-02, -2.11493969e-02, -1.06562488e-02, -2.51681097e-02,\n",
       "        3.02566923e-02,  2.46436037e-02,  8.02824646e-03, -4.36024778e-02,\n",
       "       -1.63452700e-03,  4.86512519e-02, -3.41819674e-02,  3.33032757e-03,\n",
       "       -3.41341272e-02, -3.28377634e-02,  3.41323502e-02,  1.47087686e-02,\n",
       "        8.86104256e-03, -3.64461653e-02, -1.62294731e-02, -1.41027197e-02,\n",
       "       -1.38626322e-02, -2.35116016e-02, -3.58016267e-02, -3.66845131e-02,\n",
       "       -4.12748083e-02, -3.75274904e-02,  2.41923966e-02,  3.45625989e-02,\n",
       "        3.24400328e-02, -7.54479319e-03,  2.83823647e-02, -3.39139700e-02,\n",
       "        1.96588300e-02,  9.76220518e-03, -9.48755816e-03,  4.25859205e-02,\n",
       "        2.13871263e-02, -8.52002949e-03, -3.29930782e-02, -1.60795450e-02,\n",
       "        1.83685757e-02,  3.08279432e-02,  4.97721918e-02, -2.99964193e-02,\n",
       "        4.43927087e-02,  6.60719723e-03, -3.83378267e-02,  1.67211145e-03,\n",
       "       -1.65022239e-02,  1.20637529e-02, -2.80455593e-02, -3.03153880e-02,\n",
       "        3.55556346e-02, -2.77781487e-02, -3.03872582e-02, -4.93611582e-02,\n",
       "        2.38413848e-02,  8.65733624e-03, -1.56539567e-02, -4.73118424e-02,\n",
       "        3.35697420e-02, -2.04686876e-02,  1.92235596e-02,  5.54550439e-04,\n",
       "        1.39434077e-02, -3.34932432e-02,  7.35489279e-03, -2.67171394e-02,\n",
       "        1.76291727e-02, -1.87653061e-02, -7.23714754e-03,  4.42188643e-02,\n",
       "       -3.65173221e-02,  1.34325065e-02,  3.76748554e-02,  1.88428648e-02,\n",
       "        4.79464792e-02, -1.75514594e-02,  1.87026896e-02,  5.56800514e-03,\n",
       "        2.84588970e-02,  6.85776398e-03, -3.94776948e-02, -4.28891666e-02,\n",
       "        1.42080225e-02, -3.30103785e-02, -2.32473016e-02, -1.85189359e-02,\n",
       "        4.67108749e-02, -3.96426767e-03,  4.45540994e-03, -1.31840333e-02,\n",
       "       -5.22211939e-03, -1.83593519e-02,  2.17283256e-02, -3.23583037e-02,\n",
       "       -1.51060522e-04, -2.74417400e-02,  4.16564681e-02,  2.04294957e-02,\n",
       "       -3.11280247e-02, -3.56406458e-02,  2.64085196e-02,  2.65742466e-03,\n",
       "       -7.19213486e-03,  4.96548899e-02, -5.36017492e-03,  1.29676946e-02,\n",
       "       -3.15964706e-02, -2.67223846e-02,  2.33541615e-02, -3.51504683e-02,\n",
       "       -1.11147389e-02,  3.69835831e-02,  2.10199989e-02,  3.76414135e-03,\n",
       "       -3.04945596e-02,  8.59210640e-03,  4.05218117e-02,  4.00643423e-03,\n",
       "       -1.11348145e-02, -3.53787169e-02, -1.13868490e-02, -2.81835552e-02,\n",
       "       -4.61651944e-02, -1.11465231e-02,  4.05878164e-02,  1.20659955e-02,\n",
       "        4.86838482e-02, -1.72009096e-02, -4.59965579e-02,  2.00981386e-02,\n",
       "       -5.59289381e-03, -3.66420671e-03,  4.55050543e-03,  4.13489603e-02,\n",
       "       -2.47288700e-02, -1.76101215e-02,  3.69495265e-02, -4.90393750e-02,\n",
       "       -1.97813641e-02, -4.94751222e-02,  2.10360773e-02,  8.18844885e-03,\n",
       "       -1.19945779e-02,  4.86354567e-02, -1.68573037e-02,  3.56579758e-02,\n",
       "       -1.04680657e-05, -2.05463413e-02, -3.47341895e-02,  2.95148380e-02,\n",
       "       -9.24179703e-03, -2.30298284e-02,  1.58250965e-02, -5.34065813e-03,\n",
       "        4.95889895e-02,  3.57510112e-02, -2.53977422e-02,  2.12889649e-02,\n",
       "       -3.18669155e-03,  2.71932594e-02, -4.46102619e-02, -1.63689032e-02,\n",
       "       -4.02054936e-03,  8.42448324e-03, -2.23947894e-02, -3.21285017e-02,\n",
       "        4.96503375e-02, -1.03136785e-02,  1.18481740e-02, -2.15465557e-02,\n",
       "       -2.58246195e-02, -4.27874699e-02,  1.20484121e-02, -1.77063830e-02,\n",
       "        4.51487303e-03, -2.69350894e-02, -3.16737965e-03,  3.05479430e-02,\n",
       "       -4.08163443e-02, -3.85916345e-02, -3.49185579e-02, -4.82065454e-02,\n",
       "        1.13573559e-02,  4.94096912e-02, -3.97955664e-02, -2.20171940e-02,\n",
       "       -3.90558466e-02,  4.43254597e-02,  4.41281907e-02, -2.87623890e-02,\n",
       "       -3.65520939e-02,  4.53037508e-02, -2.21753363e-02,  5.37993759e-03,\n",
       "        2.30541117e-02,  1.77746899e-02,  3.83318774e-02,  1.71194226e-03,\n",
       "       -1.95387844e-02,  3.99592854e-02, -1.09033808e-02, -1.69994719e-02,\n",
       "        2.13137753e-02, -1.86229870e-03, -4.31663170e-02,  2.96290405e-02,\n",
       "       -5.80499321e-03,  9.10509750e-03,  4.88425009e-02,  8.66714865e-03,\n",
       "        4.98544052e-03, -1.67572871e-02,  4.26069163e-02,  7.82505423e-03,\n",
       "       -2.65224930e-02, -2.02810057e-02, -1.52882561e-02, -4.70241681e-02,\n",
       "       -3.29102166e-02,  4.63416837e-02, -1.27424374e-02, -3.98681760e-02,\n",
       "        4.03901227e-02,  4.22781706e-03,  2.75840797e-02,  6.22201711e-04,\n",
       "        3.12938727e-02,  2.51568891e-02,  1.31731071e-02,  8.72982666e-03,\n",
       "       -4.41738851e-02, -2.32131369e-02, -4.57242616e-02,  4.50787209e-02,\n",
       "        3.38907167e-03,  8.97478312e-04,  3.15060280e-02,  2.48916484e-02,\n",
       "       -3.42112072e-02,  2.74450220e-02, -1.53262839e-02,  1.38195492e-02,\n",
       "       -1.28487460e-02,  3.98844369e-02, -4.40534838e-02,  1.19320303e-03,\n",
       "       -7.54226372e-03,  1.79208033e-02, -1.06801838e-03, -3.42572480e-02,\n",
       "        4.03923504e-02,  3.64985317e-03,  4.42825630e-03,  4.88922857e-02,\n",
       "       -3.80129814e-02, -2.36971024e-02, -1.60115846e-02,  5.92736155e-03,\n",
       "        4.84058298e-02,  3.62328440e-03, -2.49852538e-02, -2.68381964e-02,\n",
       "        4.79994304e-02,  1.68728344e-02,  4.92116548e-02,  4.98325340e-02,\n",
       "        3.19508649e-02, -3.11529990e-02,  3.76768000e-02,  6.23750687e-03,\n",
       "       -1.52250528e-02,  2.99770124e-02,  1.67630427e-02, -3.94028313e-02,\n",
       "        3.57725956e-02, -3.18916440e-02,  3.34714316e-02,  1.07787922e-03,\n",
       "       -8.91615078e-03, -3.91954780e-02,  2.45114677e-02,  4.89167012e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.get_weights()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attributo mask_zero=True, appiccica una mask\n",
    "embedded_sentences._keras_mask # i token di padding vengono ignorati?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nota\n",
    "Paperspace: https://www.paperspace.com/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
